{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1- Detect and crop license plates in car images.\n",
        "\n",
        "https://www.kaggle.com/datasets/andrewmvd/car-plate-detection?select=annotations\n",
        "\n",
        "\n",
        "2- detect and crop characters from license plates images.\n",
        "\n",
        "3- classify characters and print text output."
      ],
      "metadata": {
        "id": "oQ5MYdOoM3UP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdn42kFymQoT"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# !pip install tensorflow==2.4.0\n",
        "# !pip install tensorflow-gpu==2.4.0\n",
        "# !pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0\n",
        "# !pip install imageai --upgrade\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL.Image\n",
        "from PIL import ImageOps\n",
        "import PIL\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import tensorboard\n",
        "import IPython\n",
        "import sklearn\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "from imageai.Classification import ImageClassification\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Trainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"/content/drive/MyDrive/imageai/LPDS\")\n",
        "trainer.setTrainConfig(object_names_array=[\"licence\"], batch_size=8, num_experiments=30, train_from_pretrained_model=\"/content/drive/MyDrive/imageai/LPDS/models/detection_model-ex-018--loss-0014.416.h5\")\n",
        "trainer.trainModel()"
      ],
      "metadata": {
        "id": "XJKc9CNPWaTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"/content/drive/MyDrive/imageai/LPDS\")\n",
        "metrics = trainer.evaluateModel(model_path=\"/content/drive/MyDrive/imageai/LPDS/models\", json_path=\"/content/drive/MyDrive/imageai/LPDS/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "IKrnSm0_jTCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Detector\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(\"/content/drive/MyDrive/imageai/LPDS/models/detection_model-ex-029--loss-0014.191.h5\")\n",
        "detector.setJsonPath(\"/content/drive/MyDrive/imageai/LPDS/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "detections = detector.detectObjectsFromImage(input_image=\"/content/drive/MyDrive/imageai/LPDS/train/images/Cars100.png\", output_image_path=\"/content/drive/MyDrive/imageai/LP-detected.jpg\",  extract_detected_objects=True)\n",
        "#for detection in detections:\n",
        " #   print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "metadata": {
        "id": "oyfEsUp5Xunc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = ImageClassification()\n",
        "\n",
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape = (299, 299, 3),\n",
        "    include_top = True, \n",
        "    weights = \"imagenet\"                  \n",
        ")\n",
        "\n",
        "saving_path = pathlib.Path('/content/drive/MyDrive/imageai/SavedBaseModel.h5')\n",
        "\n",
        "base_model.save(saving_path)\n",
        "\n",
        "model_path = pathlib.Path('/content/drive/MyDrive/imageai/SavedBaseModel.h5')\n",
        "\n",
        "prediction.setModelTypeAsInceptionV3()\n",
        "\n",
        "prediction.setModelPath(\"/content/drive/MyDrive/imageai/SavedBaseModel.h5\")\n",
        "\n",
        "prediction.loadModel()\n",
        "\n",
        "predictions, probabilities = prediction.classifyImage(\"/content/drive/MyDrive/License_Plate_Recognition/LicPlateImages/10.png\", result_count=10)\n",
        "\n",
        "for eachPrediction, eachProbability in zip(predictions, probabilities):\n",
        "    print(eachPrediction , \" : \" , eachProbability)\n"
      ],
      "metadata": {
        "id": "OP4sm6UXmbe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 5  # labels are from 0 to 9\n",
        "\n",
        "# # Build the RNN model\n",
        "# def build_model(allow_cudnn_kernel=True):\n",
        "#     # CuDNN is only available at the layer level, and not at the cell level.\n",
        "#     # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "#     # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "#     if allow_cudnn_kernel:\n",
        "#         # The LSTM layer with default options uses CuDNN.\n",
        "#         lstm_layer = keras.layers.LSTM(units, return_state=True, input_shape=(None, input_dim))\n",
        "#         # lstm_layer = keras.layers.GRU(units, input_shape=(None, input_dim))\n",
        "#     else:\n",
        "#         # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "#         lstm_layer = keras.layers.RNN(\n",
        "#             keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "#         )\n",
        "#     model = keras.models.Sequential(\n",
        "#         [\n",
        "#            # keras.layers.Conv2D(16, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),    \n",
        "#            # keras.layers.Rescaling(scale=1/255),\n",
        "#             lstm_layer,\n",
        "#             keras.layers.BatchNormalization(),\n",
        "#             keras.layers.Dense(output_size),\n",
        "#         ]\n",
        "#     )\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "NnQNVF8p5zzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = pathlib.Path('/content/drive/MyDrive/RNNTest/dataset_characters_blackbackground')\n",
        "sample_path = pathlib.Path('/content/drive/MyDrive/imageai/LPDS/LP-detected-objects')\n",
        "\n",
        "dataset_path = tf.keras.utils.image_dataset_from_directory(        # Training dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed= 1,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(input_dim,input_dim),\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=True)\n",
        "\n",
        "\n",
        "dataset_path_val = tf.keras.utils.image_dataset_from_directory(      #Validation dataset\n",
        "    data_path,\n",
        "    labels= 'inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed= 2,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(input_dim, input_dim),\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=True)\n",
        "\n",
        "sample = tf.keras.utils.image_dataset_from_directory(\n",
        "    sample_path,\n",
        "    labels= 'inferred',\n",
        "    batch_size=1,\n",
        "    image_size=(200,200),\n",
        "    color_mode=\"grayscale\"\n",
        ")"
      ],
      "metadata": {
        "id": "3p_tINDY50SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE=tf.data.AUTOTUNE\n",
        "dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "mMSbdSWg50q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim), dropout=0.2)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(None, input_dim))\n",
        "\n",
        "x = lstm_layer(inputs)\n",
        "existing_state = lstm_layer.states\n",
        "n = keras.layers.LSTM(units, input_shape=(None, input_dim), dropout=0.2, return_sequences=True)\n",
        "y = keras.layers.BatchNormalization()(x)\n",
        "z = keras.layers.Dense(output_size)(y)\n",
        "\n",
        "model = tf.keras.Model(inputs, z)"
      ],
      "metadata": {
        "id": "d-12YQuAqxnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_lstm = tf.keras.Sequential()\n",
        "# model_lstm.add(tf.keras.layers.LSTM(units=125, activation=\"tanh\", return_sequences=True))\n",
        "# model_lstm.add(tf.keras.layers.Dense(units=1))\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    dataset_path, validation_data=dataset_path_val, batch_size=batch_size, epochs=20\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model_lstm.fit(dataset_path, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "id": "eP6GyJE66Jl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with tf.device(\"CPU:0\"):\n",
        "#     cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "#     cpu_model.set_weights(model.get_weights())\n",
        "#     sample =  np.array(sample)\n",
        "#     result = tf.argmax(cpu_model.predict(tf.expand_dims(sample, 0)), axis=1)\n",
        "#     print(\n",
        "#         \"Predicted result is: %s, target result is:\" % (result.numpy())\n",
        "#     )\n",
        "#     plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ],
      "metadata": {
        "id": "FZZaXt8k6J9T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "LPR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}